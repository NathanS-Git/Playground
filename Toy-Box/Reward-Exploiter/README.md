I had originally planned on this just being a stupid project where the RL agent defines its own reward, where the outcome would've been quite obvious (it would increase its own reward until int overflow). However, I've had a thought. The human brain naturally is its own rewarder - not the environment which is usually what defines the rewards in a typical RL setting. How can the actual human brain be in charge of rewarding itself, but this *doesn't* result in the obvious case of it just maximizing its own reward? How are our minds able to accomplish this? I mean, don't get me wrong, it messes up at times (i.e. hard drugs give massive rewards, as does scrolling through youtube all day), but it actually seems to guide a lot of what we do. The reward center is in charge of making sure I eat everyday, and I reproduce, but also why I want to do better in life, and work towards goals. Which is what I want to investigate more in this repo. Let's attempt to give robots our desires.
